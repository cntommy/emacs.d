:PROPERTIES:
:ID:       C6F43766-7830-4229-8654-D93BC2B4A2EC
:END:
#+TITLE: 鹏程工作
#+AUTHOR: Jun Gao
#+DATE: [2023-07-21 五 14:09]
#+HUGO_BASE_DIR: ~/notes
#+HUGO_SECTION: ch/docs
* 组织架构
** 智能部 强势部门，领头高文院士
*** 双聘
**** 金海 华科计算机学院院长 和刘老师关系不好 是体系结构领域的前三
*** 所？ 做大模型预训练 所长余跃 负责开源的工作
**** 王晖老师 组长？做中文数据安全
***** 雷余老师
*** 视觉所 所长 王？
**** 李革老师 和杨耀东老师关系不错
** 智算部 陈文光老师统筹 院士？
*** 体系架构研究所
**** 刘老师 组长 人还不错 华南理工教授 来鹏程准备冲院士 跟着高院士干活 和陈文光老师关系一般
**** 龚一凡老师 创业公司合伙人 鹏程全职 老婆在香港理工任职 有个孩子小简 本来跟着李睿老师 被刘老师截胡
***** 兹海 3d动作识别 王亦洲老师学生
***** 马成栋 杨耀东老师学生
***** 田稼科 自动驾驶目标检测 老师在国外 准备华工拿title 财富自由 在英特尔工作 做存储
**** 李睿老师 副研究员 负责测评的调研
**** 李玉娇 澳科院
**** 王雯老师 工程师 负责数据仓库
**** 青年突击队
**** 徐飞老师 gpu推理加速 华东师范 刘老师的第一届学生
**** 范高俊博士 负责脑海？感觉经常和大佬开会
**** 范老师 负责财务 被人搞了 不然是更高级的财务领导 原来是公司的老总
**** 於佳老师 hr 后勤 男朋友在读博
**** 郑庆华 同济大学校长 准备冲院士？ 数据做了十多年 有百度百科中英文 维基百科中英文
**** 曹绍猛 前端工程师？ 应用 跟着刘昌松
**** 王淼 清华学生 认识刘知远老师的学生
**** 刘昌松老师
*** 别的所有几个？
** 数理部 原来的强势部门，前身是广东的重点实验室，有好几个院士，但是受到管理层打压人才流失
** 合作的
*** 方明
*** 胡国强 人工智能实验室高级经理
* 聊天信息
** 如果走科研道路还是需要会social
** 华工的国际学校给的待遇不错，有分房，工资高，门槛低
** 大模型这块很难写论文，但是做出实际的东西会比较有影响力
** 北京的学校性价比都很低，这个副教授给的工资很高有70w
** 部门缺少成果，年终应该排名垫底
** 和人合作得提前想清楚，知己知彼
** 鹏程的模型先做toG 再做toB
** 公务员电脑不再用国产了，税务局可以配3090
** 香港的人喜欢户外运动，有老师招学生有这个要求
** 开源的评测集就不会被闭源的数据攻击
** 扩充词表继续train的效果  不如从头开始train的效果好
** 有同学在LLaMA上加训维基百科数据，同时构造了一些监督信号，auto-regressive形式 a.13B及以下，全量调参，明显提升
** 范老师想给海哥介绍对象，想要让於佳老师操作
** 杨老师说不仅要贴钱、贴人还要贴算力
** meta训练opt的时候也有20%的容错，孙博只有5%
** 成栋在投NMI
** diffusion灵感来源于物理，songyang做的比较好，结合rl现在搞的比较好
** 龚老师外号娱乐CEO，喜欢德式桌游，之前做hps
** 海哥有个资源密集型的师兄叫学海，有个搞竞赛的师兄不喜欢发论文只喜欢coding现在在摆百川
** 玉娇学姐去澳科院读博后，
** 如果走教职需要海外读博后，交换也可以
** psro是从多个策略的对抗中找到最好策略的方法，夹角变大是优化的目标
** DETR是用transformer目标检测算法，部署的话fast-cnn等更好
** 沈向洋在深圳有idea研究院，工作有点累
** nips现在都是拼实验
**
* 会议记录
** 部门周会
*** 时间：<2024-07-21 日>
*** 目标：总结+安排
*** 会议记录：
**** 模型的结构不影响训练结果，只是训练技术不一样
**** 需要有一些训练算法的创新，或者系统级的创新（如并行）
**** 稠密性和稀疏性：稠密是指所有参数一起训练
**** 数据工具会放在智算部
** 刘老师办公室
*** 时间：<2023-07-24 一>
*** 目标：小组内讨论怎么资源交换
*** 会议记录
**** 脑海模型pretrain 缺少知识类数据，想要wiki 目前可以通过chatmind来获取用户反馈,https://pangu-alpha.pcl.ac.cn/chatmind/,caoshm
**** 飞轮可以用于标注SFT数据
** 部门间交流
*** 会议记录：
*** 时间：<2023-07-26 三>
*** 目标：1 拿到想要的数据 2 SFT打通 3撬动500人标数据
*** 具体事项
**** 郑校长给的数据集质量如何 海哥完成
**** 设计一个方案标注rlhf数据 海哥草稿
**** 梳理双方需求，数据和codebase需要放在智算部，拿到精调的数据和精调工具
***** 问同济标注经验
** 领导汇报
*** 时间：<2023-07-28 五>
*** 目标：向陈老师展示1环境部署工具 2sft效果展示问答 3测评 4求助
*** 会议记录
**** ceval评测指标的重要性
**** 预训练阶段就应该看各种知识，sft应该在5%-10%计算量之间
**** pretrain 60-70 sft 80-90 rlhf 95
**** 需要拿别的基础模型交叉对比
**** 200张卡 36个节点
**** tuna 镜像可以 问昌松
**** 机内做个模型并行   流水并行不是很重要
**** 田七 mindspot   平衡型250P
**** sft 100w 100块卡 1天
**** 新华网也要做自己的sft数据
**** 抛开华为 需要自己搭环境  华为的环境是高老师的推广点
**** 数据清洗刘老师不敢碰  英文数据的清洗好像还有问题  中文数据清洗已经有方法了   还有一些工作可以
**** 网信办规定中文wiki不能用  郑庆华他们做了什么清洗
**** 学vicuna的套路，高质量人写prompt+回答+用户偏好，做中文的榜单，分题答案全部开源
**** 兵器谱 评测数据集
***** 测试集用模型生成，避免数据泄露
*****
***** 合作团队
****** 清华翟季东（军事应用 性能评测） 启元（训练微调） 北大 智源
****** 王晖老师 贾焰老师
**** 吴任 百度 数据测试集造假
**** 怎么回答自己的模型效果怎么样
**** 要不就提出一个metric  其他的就不要增加复杂度
** 孙睿阳 数据评测交流
*** <2023-07-26 三>
*** 目标：了解做的内容，有没有能参与的工作，能不能合作
*** 会议记录：
**** 8.15基本结果 开源评测工具集
**** lm-evaluation-harness
**** 多轮  污染性 safe
** 模拟汇报
*** 时间：<2023-07-27 四>
*** 目标：走一遍周五报告的流程
*** 会议记录：
**** 徐飞老师 ccf-cis会议 bestpaper 还会有硕士生来 在阿里 熟悉deepspeed
**** 王老师不想和刘老师推进，刘老师找到了余悦所长继续谈
** 智能部交流
*** <2023-07-31 一>
*** 交流经验
*** 会议记录
**** 用dpo不用太大的显存，本质也是on-policy,但是可以用自回归损失
**** 200B有rope rmws
**** 方院士要求100%符合网信办的要求
**** 7B的使用megtron训的
**** 预训练在高质量数据集多训几轮，提升广度可能效果不大
**** llama2 sft10k rlhf300w
**** reward在合规上准确率 91%  hh上67%左右 很少有超过80%的
**** raft+dpo
**** 想要仿照llama2 多一个多阶段的rlhf
**** sft之后分trlx数还降了
**** 提供一个正式的报告
**** 200B的模型一天只能吃10g的数据
**** hhhfp数据还没用上  打分的数据也没用起来   只用了1w条数据
**** 准备做机柜间并行
**** tlrx框架
** 组会
*** <2023-08-04 五>
*** 会议记录
**** 可以用别的7B模型，也可以做自己的预训练，把全链条都覆盖，也可以在算法上有点创新
**** 全貌图 https://arxiv.org/pdf/2303.18223.pdf
***** 数据采集：httrack 启智飞轮
***** 数据处理：特定的（gpt4反向  ） 共性的需求（隐私 去重 ）
***** 模型训练：昇思
***** 模型微调：trlx
***** 模型评测：opencompass上海交大
***** 模型部署：青年突击队在做模型压缩
**** llama有个continue training 效果也不是很好 https://github.com/FlagAlpha/Llama2-Chinese
**** 新华社30-60块一条数据
**** sft rlhf 评测（loss 安全 gpt4） 攻击
**** 工作量要呈现饱满
** 龙猫api对接
*** <2023-08-07 一>
*** 目标
**** 确定api的报价
**** 提供类似的供应商报价
***** https://www.quantumore.com/%e4%ba%a7%e5%93%81%e4%b8%8e%e6%9c%8d%e5%8a%a1/
**** api具体服务
| 渠道   | 速度 | 直连 | 溢价 | 稳定性    |
|--------+------+------+------+-----------|
| 龙猫   | 官方 | 是   |  40% | 翻墙+封号 |
| 宽土猫 | -20% | 否   |  10% | 数据安全  |
| azure  |      | 是   |      | 排队      |
|        |      |      |      |           |

** mindspore和llama2
*** <2023-08-07 一>
*** 会议记录
**** 200B的模型是用llama，先做了pipline并行，再做数据并行

** 8.31
杨建昆 鹏程实验室主任助理
7B GPU 训练了936B token loss2.17
200B 回退到613B 十月上旬才能完成1T token

qinglianghua
gptq+exllama

数据标注组
42105次回答 拥有37348条

** 组会<2023-09-08 五>
*** 会议记录
* 数据库
** 清洗wiki的数据
*** 提取有用的信息 https://blog.51cto.com/u_15919249/5962434
*** 构造问题的方式
**** https://gitcode.net/mirrors/tatsu-lab/stanford_alpaca?utm_source=csdn_github_accelerator
**** https://github.com/bigscience-workshop/promptsource
**** 海哥问百川那边的yiyang？
** 组会<2023-09-15 五>
*** 会议记录
**** 鹏城 国家 深圳 部门 各赚1/3
**** cncf qupis qps 谷歌
**** 先把问题提出来，不一定要解决
**** rlhf的问题 1sft不够好 2token太长 gme估计不太准确
**** 陈老师要的是pretrain的还是sft的？
* 评测榜单
智源
gaokao
kola
opencompass
清华大学
z-bench
c-eval

预训练模型
/home/pcluser/rlhf/output/pretrain_model

训练脚本
/home/pcluser/rlhf/scripts/sft-deepspeed.sh

数据处理脚本
/home/pcluser/rlhf/safe_rlhf/datasets/raw/alpaca.py

处理好的moss数据
/home/pcluser/rlhf/moss_datasets
/home/pcluser/rlhf/bc_datasets/firefly_0_mod.json/

看一下baichuan的数据有没有多轮
是不是都是一样的格式

* sft记录

** 训练
| name       | length | epoch | batch | accum | gpu |    lr |   step | c-eval | 对话 |
|------------+--------+-------+-------+-------+-----+-------+--------+--------+------|
| sft-bc     |    512 |     3 |     2 |     4 |  16 |  2e-5 |        |     26 |      |
| sft-bc-2   |        |       |       |       |     |       |        |        |      |
| sft-bc-10w |    512 |     6 |    8? |     2 |  16 | 4e-5? |        |  20.43 | 好   |
| sft-bc-3   |    512 |     6 |     4 |     4 |  16 |  4e-5 | 130000 |        |      |
|            |        |       |       |       |     |       |  60000 |  21.79 |      |
| sft-bc-4   |    512 |     6 |     2 |     4 |  16 |  2e-5 |        |        |      |

** bug
*** fused_adam.so: cannot open shared object file: No such file or directory
**** ~/anaconda3/envs/safe-rlhf目录下lib要改为lib64
*** 无论mini batch 2 4 8 内存都是20G左右没有变化
** c-eval测试脚本
*** CUDA_VISIBLE_DEVICES=6 python -m eval.my_eval_all --model_path output/sft-bc-3  --few_shot
** 多轮测试脚本
*** CUDA_VISIBLE_DEVICES=4 python -m safe_rlhf.serve.cli --model_name_or_path output/sft-bc-10w
CUDA_VISIBLE_DEVICES=4 python -m safe_rlhf.serve.cli --model_name_or_path /mnt/pcluser/Code/rlhf/output/sft-moss-new/7000
*** 训练的时候ssh出问题
**** 检查docker起来没
***** sudo docker ps -q
**** 检查ssh服务
***** 进入docker : sudo docker exec -it 00b85b909936 /bin/bash
***** service ssh status
**** 重启服务
***** systemctl restart re-local.service
**** 退出容器
***** exit
* 反向prompt
** 问题
*** 有重复的问题
{"question": "什么是棘手问题？", "answer": "棘手问题是指一个困难或不可能解决的问题，因为这个问题不完整、矛盾、不断变化且往往难以识别或定义。"}
{"question": "什么是棘手问题？", "answer": "棘手问题是指在社会政策问题领域中，由于缺乏明确的问题定义以及涉及不同利益关系人的复杂观点而无法应用纯粹>的科学或工程方法解决的问题。这种问题通常具有不明确的定义，没有既定的发展方向，并涉及具有不同观点的利益关系人，没有简单的解决方案。因此，解决棘手问>题需要提出具有创造性的方法。"}
*** 缺乏上下文
{"question": "这种物种在哪些地方可以找到？", "answer": "这种物种可以在潮间带至浅海泥沙底的地方找到。"}
*** 报错
Traceback (most recent call last):
  File "/root/gaojun/wiki_prompt_construct/inst_construct.py", line 136, in <module>
    inst_construct(p, file, output, key)
  File "/root/gaojun/wiki_prompt_construct/inst_construct.py", line 38, in inst_construct
    lines = rf.readlines()
  File "/root/anaconda3/envs/openai3_9/lib/python3.9/codecs.py", line 322, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe4 in position 0: unexpected end of data
* 暹星杯
** 背景：主要是面向实验室内部人员的，去年举行过一届，当时只有一个赛道；今年是第二届，考虑三到四个赛道，今年在赛道设置上要紧密贴近我们的大模型，另外因为大模型训练使用，能给大赛使用的npu资源不会太多
*** 数据、工具，建议涵盖在题目中
** 目的：通过大赛收集一些数据
*** 搜集sft数据，或者prompt数据
** 疑问：
*** 怎么通过评测赛道搜集评测数据
*** 有没有类似的比赛能参考
